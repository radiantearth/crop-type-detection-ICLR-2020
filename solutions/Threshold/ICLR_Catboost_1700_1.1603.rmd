---
title: "ICLR Crop detection"
author: "Dr Fad"
date: "Feb 17, 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Load libraries

```{r cars}
rm(list = ls())
# library(keras)
# library(tensorflow)
library(EBImage)
# use_condaenv("r-tensorflow")
# install_keras()
# library(sf)
# library(spdep)
library(rgdal)

## Import packages
library(ggplot2)
library(gridExtra)
library(repr)
library(dplyr)
library(caret)
library(e1071)
library(MLmetrics)
library(klaR)
library(gdalUtils)
library(raster) #Manipulating geospatil images
library(sqldf) #Running sql type of query
library(Matrix) # For matrix conversion used for xgboost
library(beepr) #For output sound
library(stringi) #For text manipulation
library(stringr) #For text manipulation
library(lubridate) #For manipulating dates
library(geosphere) #For getting distance from geospatial data i.e long and lat
library(factoextra) #To visualise clusters
library(fpc) # for computing density based clustering
library(dbscan) # for computing density based clustering
library(tictoc) #To calculate running time
library(mapproj) #To map projections
library(catboost) #For modelling
library(Boruta)#For feature selection
library(xgboost)
library(Matrix)
# library(lightgbm)
library(ROCR) #Visualising performance of classifiers

options(repr.plot.width=4, repr.plot.height=4)
options(scipen=99999999) # Used to revoke display of scientific numbers
```

#Load rda's
```{r}
# load("ICLR_NDVI.rda")
```


##Read load and test
```{r}
tic()
ICLR <- read.csv("C:/Users/A199702/Documents/Zindi/Crop Recognition/completed data.csv")
Sample_sub <- read.csv("C:/Users/A199702/Documents/Zindi/Crop Recognition/SampleSubmission.csv")
Sample_sub <- Sample_sub[,c(1,2)]
#Change column name
colnames(ICLR)[1] <- "Field_ID"
ICLR_test <- merge(Sample_sub, ICLR, by = "Field_ID", all.y=T)
ICLR_train <- ICLR_test[is.na(ICLR_test$Crop_ID_1),]
ICLR_test <- ICLR_test[!is.na(ICLR_test$Crop_ID_1),]
#Drop dummy column
ICLR_train$Crop_ID_1 <- NULL
ICLR_test$Crop_ID_1 <- NULL

ICLR_train[,c("row_loc","col_loc","tile")] <- NULL
ICLR_test[,c("row_loc","col_loc","tile")] <- NULL


head(ICLR_train)
toc()
```

#Feature Engineering
Get standard deviations
Didn't work

```{r}
# ICLR_train_sd <- ICLR_train
# ICLR_test_sd <- ICLR_test
# 
# ICLR_train_sd <- ICLR_train_sd %>% group_by(Field_ID,label) %>% summarise_all(funs(sd))
# ICLR_test_sd <- ICLR_test_sd %>% group_by(Field_ID,label) %>% summarise_all(funs(sd))
# table(ICLR_train$label)
# ICLR_train_sd <- as.data.frame(ICLR_train_sd)
# ICLR_test_sd <- as.data.frame(ICLR_test_sd)
# colnames(ICLR_train_sd) <- c(colnames(ICLR_train_sd)[1:2],paste0(colnames(ICLR_train_sd)[3:171],"_sd"))
# colnames(ICLR_test_sd) <- c(colnames(ICLR_test_sd)[1:2],paste0(colnames(ICLR_test_sd)[3:171],"_sd"))
# 
# #Replace NaN's with 0
# is.nan.data.frame <- function(x)
# do.call(cbind, lapply(x, is.nan))
# 
# ICLR_train_sd[is.nan(ICLR_train_sd)] <- 0
# ICLR_test_sd[is.nan(ICLR_test_sd)] <- 0

```

Get Area of each field
```{r}
# ICLR_Area <- rbind(ICLR_train,ICLR_test)
# ICLR_Area <- ICLR_Area[,c('Field_ID',"row_loc","col_loc")]
# ICLR_Area <- ICLR_Area %>% group_by(Field_ID) %>% summarise(rowmin = min(row_loc),
#                                                             rowmax = max(row_loc),
#                                                             colmin = min(col_loc),
#                                                           colmax = max(col_loc))
# ICLR_Area$Area <- ((ICLR_Area$rowmax - ICLR_Area$rowmin)+1)*((ICLR_Area$colmax - ICLR_Area$colmin)+1)
# ICLR_Area <- ICLR_Area[,c("Field_ID","Area")]
```



```{r}
bands <- c("B01","B02","B03","B04","B05","B06","B07","B08","B8A","B09","B11","B12","CLD")
dt <- c("0606","0701","0706","0711","0721","0805","0815","0825","0909","0919","0924","1004","1103")

##########################################################################
#NDVI train
##########################################################################
for (i in seq(1,13,1)){
 ICLR_train[,paste0("NDVI","_",dt[i])] <- (ICLR_train[,paste0("B08","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])])/(ICLR_train[,paste0("B08","_2019",dt[i])] + ICLR_train[,paste0("B04","_2019",dt[i])]) 
}

#NDVI test
for (i in seq(1,13,1)){
 ICLR_test[,paste0("NDVI","_",dt[i])] <- (ICLR_test[,paste0("B08","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])])/(ICLR_test[,paste0("B08","_2019",dt[i])] + ICLR_test[,paste0("B04","_2019",dt[i])]) 
}


##########################################################################
#NDRE5 train
##########################################################################
for (i in seq(1,13,1)){
 ICLR_train[,paste0("NDRE5","_",dt[i])] <- (ICLR_train[,paste0("B05","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])])/(ICLR_train[,paste0("B05","_2019",dt[i])] + ICLR_train[,paste0("B04","_2019",dt[i])])
}

#NDRE5 test
for (i in seq(1,13,1)){
 ICLR_test[,paste0("NDRE5","_",dt[i])] <- (ICLR_test[,paste0("B05","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])])/(ICLR_test[,paste0("B05","_2019",dt[i])] + ICLR_test[,paste0("B04","_2019",dt[i])])
}

##########################################################################
#Multiply row and col
##########################################################################
# ICLR_train$col_of_row <- ICLR_train$row_loc * ICLR_train$col_loc
# ICLR_test$col_of_row <- ICLR_test$row_loc * ICLR_test$col_loc


##########################################################################
#WDRVI train 
##########################################################################
for (i in seq(1,13,1)){
 ICLR_train[,paste0("WDRVI","_",dt[i])] <- (8*ICLR_train[,paste0("B08","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])])/(8*ICLR_train[,paste0("B08","_2019",dt[i])] + ICLR_train[,paste0("B04","_2019",dt[i])])
}

#WDRVI test
for (i in seq(1,13,1)){
 ICLR_test[,paste0("WDRVI","_",dt[i])] <- (8*ICLR_test[,paste0("B08","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])])/(8*ICLR_test[,paste0("B08","_2019",dt[i])] + ICLR_test[,paste0("B04","_2019",dt[i])])
}

##########################################################################
#NDRE6 train - dropped
##########################################################################
# for (i in seq(1,13,1)){
#  ICLR_train[,paste0("NDRE6","_",dt[i])] <- (ICLR_train[,paste0("B06","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])])/(ICLR_train[,paste0("B06","_2019",dt[i])] + ICLR_train[,paste0("B04","_2019",dt[i])])
# }
# 
# #NDRE6 test
# for (i in seq(1,13,1)){
#  ICLR_test[,paste0("NDRE6","_",dt[i])] <- (ICLR_test[,paste0("B06","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])])/(ICLR_test[,paste0("B06","_2019",dt[i])] + ICLR_test[,paste0("B04","_2019",dt[i])])
# }

##########################################################################
#NDRE7 train- dropped
##########################################################################
for (i in seq(1,13,1)){
 ICLR_train[,paste0("NDRE7","_",dt[i])] <- (ICLR_train[,paste0("B07","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])])/(ICLR_train[,paste0("B07","_2019",dt[i])] + ICLR_train[,paste0("B04","_2019",dt[i])])
}

#NDRE7 test
for (i in seq(1,13,1)){
 ICLR_test[,paste0("NDRE7","_",dt[i])] <- (ICLR_test[,paste0("B07","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])])/(ICLR_test[,paste0("B07","_2019",dt[i])] + ICLR_test[,paste0("B04","_2019",dt[i])])
}

##########################################################################
#NDSI train- dropped
##########################################################################
# for (i in seq(1,13,1)){
#  ICLR_train[,paste0("NDSI","_",dt[i])] <- (ICLR_train[,paste0("B04","_2019",dt[i])] - ICLR_train[,paste0("B06","_2019",dt[i])])/(ICLR_train[,paste0("B04","_2019",dt[i])] + ICLR_train[,paste0("B06","_2019",dt[i])])
# }
# 
# #NDSI test
# for (i in seq(1,13,1)){
#  ICLR_test[,paste0("NDSI","_",dt[i])] <- (ICLR_test[,paste0("B04","_2019",dt[i])] - ICLR_test[,paste0("B06","_2019",dt[i])])/(ICLR_test[,paste0("B04","_2019",dt[i])] + ICLR_test[,paste0("B06","_2019",dt[i])])
# }



##########################################################################
#VARI train- dropped
##########################################################################
for (i in seq(1,13,1)){
 ICLR_train[,paste0("VARI","_",dt[i])] <- (ICLR_train[,paste0("B03","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])])/(ICLR_train[,paste0("B03","_2019",dt[i])] + ICLR_train[,paste0("B04","_2019",dt[i])] - ICLR_train[,paste0("B02","_2019",dt[i])])
}

#VARI test
for (i in seq(1,13,1)){
 ICLR_test[,paste0("VARI","_",dt[i])] <- (ICLR_test[,paste0("B03","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])])/(ICLR_test[,paste0("B03","_2019",dt[i])] + ICLR_test[,paste0("B04","_2019",dt[i])] - ICLR_test[,paste0("B02","_2019",dt[i])])
}

##########################################################################
#MTCI train- dropped
##########################################################################
for (i in seq(1,13,1)){
 ICLR_train[,paste0("MTCI","_",dt[i])] <- (ICLR_train[,paste0("B8A","_2019",dt[i])] - ICLR_train[,paste0("B06","_2019",dt[i])])/(ICLR_train[,paste0("B06","_2019",dt[i])] + ICLR_train[,paste0("B07","_2019",dt[i])])
}

#MTCI test
for (i in seq(1,13,1)){
 ICLR_test[,paste0("MTCI","_",dt[i])] <- (ICLR_test[,paste0("B8A","_2019",dt[i])] - ICLR_test[,paste0("B06","_2019",dt[i])])/(ICLR_test[,paste0("B06","_2019",dt[i])] + ICLR_test[,paste0("B07","_2019",dt[i])])
}

##########################################################################
#GRVI train- dropped
##########################################################################
# for (i in seq(1,13,1)){
#  ICLR_train[,paste0("GRVI","_",dt[i])] <- (ICLR_train[,paste0("B08","_2019",dt[i])] )/(ICLR_train[,paste0("B03","_2019",dt[i])] )
# }
# 
# #GRVI test
# for (i in seq(1,13,1)){
#  ICLR_test[,paste0("GRVI","_",dt[i])] <- (ICLR_test[,paste0("B08","_2019",dt[i])] )/(ICLR_test[,paste0("B03","_2019",dt[i])] )
# }

##########################################################################
#Exblue train- (2B2- B3 - B4)Fairly good
##########################################################################
for (i in seq(1,13,1)){
 ICLR_train[,paste0("exblue","_",dt[i])] <- 2*ICLR_train[,paste0("B02","_2019",dt[i])] - ICLR_train[,paste0("B03","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])]
}

#exblue test
for (i in seq(1,13,1)){
 ICLR_test[,paste0("exblue","_",dt[i])] <- 2*ICLR_test[,paste0("B02","_2019",dt[i])] - ICLR_test[,paste0("B03","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])]
}

##########################################################################
#Exgreen train- (2B2- B3 - B4)Fairly good
##########################################################################
for (i in seq(1,13,1)){
 ICLR_train[,paste0("exgreen","_",dt[i])] <- 2*ICLR_train[,paste0("B03","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])] - ICLR_train[,paste0("B02","_2019",dt[i])]
}

#Exgreen test
for (i in seq(1,13,1)){
 ICLR_test[,paste0("exgreen","_",dt[i])] <- 2*ICLR_test[,paste0("B03","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])] - ICLR_test[,paste0("B02","_2019",dt[i])]
}
dim(ICLR_train)

##########################################################################
#Area- (lenght * breadth)
##########################################################################
# ICLR_train <- merge(ICLR_Area, ICLR_train, by = "Field_ID", all.y = T )
# ICLR_test <- merge(ICLR_Area, ICLR_test, by = "Field_ID", all.y = T )

##########################################################################
#SAVI train- dropped
##########################################################################
for (i in seq(1,13,1)){
 ICLR_train[,paste0("SAVI","_",dt[i])] <- ((ICLR_train[,paste0("B08","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])] )/(ICLR_train[,paste0("B08","_2019",dt[i])] + ICLR_train[,paste0("B04","_2019",dt[i])] + 0.428))*1.428
}

#SAVI test
for (i in seq(1,13,1)){
 ICLR_test[,paste0("SAVI","_",dt[i])] <- ((ICLR_test[,paste0("B08","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])] )/(ICLR_test[,paste0("B08","_2019",dt[i])] + ICLR_test[,paste0("B04","_2019",dt[i])] + 0.428))*1.428
}

##########################################################################
#WDRVI08 train at 0.8
##########################################################################
# for (i in seq(1,13,1)){
#  ICLR_train[,paste0("WDRVI08","_",dt[i])] <- (0.8*ICLR_train[,paste0("B08","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])])/(0.8*ICLR_train[,paste0("B08","_2019",dt[i])] + ICLR_train[,paste0("B04","_2019",dt[i])])
# }
# 
# #WDRVI08 test
# for (i in seq(1,13,1)){
#  ICLR_test[,paste0("WDRVI08","_",dt[i])] <- (0.8*ICLR_test[,paste0("B08","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])])/(0.8*ICLR_test[,paste0("B08","_2019",dt[i])] + ICLR_test[,paste0("B04","_2019",dt[i])])
# }
dim(ICLR_train)

```
#Save as rda to engineer other features that gets quantiles and min max in days

```{r}
# save(ICLR_train,ICLR_test, file= "ICLR.rda")
```





#Explore cloud cover effect
```{r}
# Cloud <- ICLR_train[,c("CLD_20190606","CLD_20190701","CLD_20190706","CLD_20190711"
#                                     ,"CLD_20190721","CLD_20190805","CLD_20190815","CLD_20190825",
#                                     "CLD_20190909","CLD_20190919","CLD_20190924","CLD_20191004",
#                                     "CLD_20191103")]
# Cloud$dummy <- 1
# Cloud <- Cloud %>% group_by(dummy) %>% summarise_all(funs(mean))
# Cloud
```
#Aggregate data
```{r}
ICLR_train <- ICLR_train %>% group_by(Field_ID,label) %>% summarise_all(funs(mean))
ICLR_test <- ICLR_test %>% group_by(Field_ID,label) %>% summarise_all(funs(mean))
table(ICLR_train$label)
ICLR_train <- as.data.frame(ICLR_train)
ICLR_test <- as.data.frame(ICLR_test)

#Cbind sd data
# ICLR_train <- cbind(ICLR_train, ICLR_train_sd[,c(3:171)])
# ICLR_test <- cbind(ICLR_test, ICLR_test_sd[,c(3:171)])

#Try remove 0805 data due to large cloud presence
# ICLR_train[,c(68:80)]

```
Dropped VDVI
#Data Exploration
```{r}
visual <- ICLR_train
visual$label <- factor(visual$label)
plot_box <- function(df, cols, col_x = 'label'){
  options(repr.plot.width = 4, repr.plot.height = 3.5)
  for(col in cols){
    p = ggplot(df, aes_string(col_x,col)) +
      geom_boxplot() +
      ggtitle(paste('Box plot of ', col, '\n vs. ', col_x))
    print(p)
  }
}

num_cols = colnames(visual[,c(1:5,172:184)])
plot_box(visual, num_cols)
```

#Add min and max values plus their difference
```{r}
#Min max for NDVI
ICLR_train$NDVI_min <- apply(ICLR_train[,c(172:184)], 1, FUN=min)
ICLR_train$NDVI_max <- apply(ICLR_train[,c(172:184)], 1, FUN=max)
ICLR_train$NDVI_diff <- ICLR_train$NDVI_max - ICLR_train$NDVI_min

ICLR_test$NDVI_min <- apply(ICLR_test[,c(172:184)], 1, FUN=min)
ICLR_test$NDVI_max <- apply(ICLR_test[,c(172:184)], 1, FUN=max)
ICLR_test$NDVI_diff <- ICLR_test$NDVI_max - ICLR_test$NDVI_min


#Min max for NDRE5
ICLR_train$NDRE5_min <- apply(ICLR_train[,c(185:197)], 1, FUN=min)
ICLR_train$NDRE5_max <- apply(ICLR_train[,c(185:197)], 1, FUN=max)
ICLR_train$NDRE5_diff <- ICLR_train$NDRE5_max - ICLR_train$NDRE5_min

ICLR_test$NDRE5_min <- apply(ICLR_test[,c(185:197)], 1, FUN=min)
ICLR_test$NDRE5_max <- apply(ICLR_test[,c(185:197)], 1, FUN=max)
ICLR_test$NDRE5_diff <- ICLR_test$NDRE5_max - ICLR_test$NDRE5_min

#Min max for WDRVI
ICLR_train$WDRVI_min <- apply(ICLR_train[,c(198:210)], 1, FUN=min)
ICLR_train$WDRVI_max <- apply(ICLR_train[,c(198:210)], 1, FUN=max)
ICLR_train$WDRVI_diff <- ICLR_train$WDRVI_max - ICLR_train$WDRVI_min

ICLR_test$WDRVI_min <- apply(ICLR_test[,c(198:210)], 1, FUN=min)
ICLR_test$WDRVI_max <- apply(ICLR_test[,c(198:210)], 1, FUN=max)
ICLR_test$WDRVI_diff <- ICLR_test$WDRVI_max - ICLR_test$WDRVI_min

#Min max for NDRE7
ICLR_train$NDRE7_min <- apply(ICLR_train[,c(211:223)], 1, FUN=min)
ICLR_train$NDRE7_max <- apply(ICLR_train[,c(211:223)], 1, FUN=max)
ICLR_train$NDRE7_diff <- ICLR_train$NDRE7_max - ICLR_train$NDRE7_min

ICLR_test$NDRE7_min <- apply(ICLR_test[,c(211:223)], 1, FUN=min)
ICLR_test$NDRE7_max <- apply(ICLR_test[,c(211:223)], 1, FUN=max)
ICLR_test$NDRE7_diff <- ICLR_test$NDRE7_max - ICLR_test$NDRE7_min

#Min max for SAVI
ICLR_train$SAVI_min <- apply(ICLR_train[,c(276:288)], 1, FUN=min)
ICLR_train$SAVI_max <- apply(ICLR_train[,c(276:288)], 1, FUN=max)
ICLR_train$SAVI_diff <- ICLR_train$SAVI_max - ICLR_train$SAVI_min

ICLR_test$SAVI_min <- apply(ICLR_test[,c(276:288)], 1, FUN=min)
ICLR_test$SAVI_max <- apply(ICLR_test[,c(276:288)], 1, FUN=max)
ICLR_test$SAVI_diff <- ICLR_test$SAVI_max - ICLR_test$SAVI_min
```

#Add quantile data
Top 8
```{r}
# Run ICLR quantiles before proceeding
load("ICLR_qt8.rda") #For top12

ICLR_train <- merge(ICLR_qt_train,ICLR_train, by = "Field_ID", all.y= T)
ICLR_test <- merge(ICLR_qt_test,ICLR_test, by = "Field_ID", all.y= T)

#To ensure field_ID and label are cols 1 n 2
ICLR_train <- ICLR_train %>% group_by(Field_ID,label) %>% summarise_all(funs(mean))
ICLR_test <- ICLR_test %>% group_by(Field_ID,label) %>% summarise_all(funs(mean))
table(ICLR_train$label)
ICLR_train <- as.data.frame(ICLR_train)
ICLR_test <- as.data.frame(ICLR_test)
```

```{r}
# # #NDVI Drop
# # ICLR_train <- merge(ICLR_NDVI_train,ICLR_train, by = "Field_ID", all.y= T)
# # ICLR_test <- merge(ICLR_NDVI_test,ICLR_test, by = "Field_ID", all.y= T)
# 
# #NDRE5
# load("ICLR_NDRE5.rda")
# ICLR_train <- merge(ICLR_NDRE5_train,ICLR_train, by = "Field_ID", all.y= T)
# ICLR_test <- merge(ICLR_NDRE5_test,ICLR_test, by = "Field_ID", all.y= T)
# # 
# #WDRVI
# load("ICLR_WDRVI.rda")
# ICLR_train <- merge(ICLR_WDRVI_train,ICLR_train, by = "Field_ID", all.y= T)
# ICLR_test <- merge(ICLR_WDRVI_test,ICLR_test, by = "Field_ID", all.y= T)
# 
# #NDRE7
# load("ICLR_NDRE7.rda")
# ICLR_train <- merge(ICLR_NDRE7_train,ICLR_train, by = "Field_ID", all.y= T)
# ICLR_test <- merge(ICLR_NDRE7_test,ICLR_test, by = "Field_ID", all.y= T)
# 
# #MTCI
# load("ICLR_MTCI.rda")
# ICLR_train <- merge(ICLR_MTCI_train,ICLR_train, by = "Field_ID", all.y= T)
# ICLR_test <- merge(ICLR_MTCI_test,ICLR_test, by = "Field_ID", all.y= T)
# 
# #SAVI
# load("ICLR_SAVI.rda")
# ICLR_train <- merge(ICLR_SAVI_train,ICLR_train, by = "Field_ID", all.y= T)
# ICLR_test <- merge(ICLR_SAVI_test,ICLR_test, by = "Field_ID", all.y= T)
# 
# ########
# #To ensure field_ID and label are cols 1 n 2
# ICLR_train <- ICLR_train %>% group_by(Field_ID,label) %>% summarise_all(funs(mean))
# ICLR_test <- ICLR_test %>% group_by(Field_ID,label) %>% summarise_all(funs(mean))
# table(ICLR_train$label)
# ICLR_train <- as.data.frame(ICLR_train)
# ICLR_test <- as.data.frame(ICLR_test)

```

#Add maturity
```{r}
# load("ICLR_mat3.rda") #For top12
# 
# ICLR_train <- merge(ICLR_mat_train,ICLR_train, by = "Field_ID", all.y= T)
# ICLR_test <- merge(ICLR_mat_test,ICLR_test, by = "Field_ID", all.y= T)
# 
# #To ensure field_ID and label are cols 1 n 2
# ICLR_train <- ICLR_train %>% group_by(Field_ID,label) %>% summarise_all(funs(mean))
# ICLR_test <- ICLR_test %>% group_by(Field_ID,label) %>% summarise_all(funs(mean))
# table(ICLR_train$label)
# ICLR_train <- as.data.frame(ICLR_train)
# ICLR_test <- as.data.frame(ICLR_test)
```

#Feature selection using Boruta
```{r}
# library(Boruta)
# # Traffic_Boruta <- Traffic #For the Boruta package
# # summary(Churn_Boruta)
# # library(doParallel)
# # registerDoParallel(cores = 4)
# set.seed(777)
# system.time(
# ICLR_Boruta_Out <- Boruta(Field_ID ~ . - label, data=ICLR_train, doTrace=2)
# )
# ICLR_boruta_signif <- names(ICLR_Boruta_Out$finalDecision[ICLR_Boruta_Out$finalDecision %in% c("Confirmed","Tentative")])  # collect Confirmed and Tentative variables
# # print(Traffic_boruta_signif)  # significant variables
# 
# plot(ICLR_Boruta_Out, cex.axis=0.6, las=2, xlab="", main="Variable Importance")   # plot variable importance
# grid(ny = 100, lty = "dotted",lwd = 2)
# save(ICLR_boruta_signif,ICLR_Boruta_Out, file = "ICLR_Boruta_F3b26.rda")
```
#Load Boruta object and subset data

```{r}
# load("ICLR_Boruta_F3b26.rda")
# ICLR_train <- ICLR_train[,c("Field_ID","label",ICLR_boruta_signif)]
# ICLR_test <- ICLR_test[,c("Field_ID","label",ICLR_boruta_signif)]

```


##Balance Data using SMOTE
```{r}
# library(UBL) #For SMOOTE
# ICLR_train$label <- factor(ICLR_train$label)
# table(ICLR_train$label)
# set.seed(200)
# 
# # ICLR_train<-  SmoteClassif(label ~ ., ICLR_train, list(`1` = 1, `2` = 1.76,`3` = 14.92, `4` = 3, `5`= 8.5,`6` = 9.14,`7`=18.74))#1400
# ICLR_train<-  SmoteClassif(label ~ ., ICLR_train, list(`1` = 1, `2` = 1.76,`3` = 14.92, `4` = 4.5, `5`= 12.75,`6` = 13.71,`7`=28.11))#1700
# 
# table(ICLR_train$label)
```
#Parameter Tuning

```{r}
# tic()
# input_x <- as.matrix(ICLR_train[,-c(1,2)])
# input_y <- factor(ICLR_train$label) #must be factors
# levels(input_y) <- c("X1", "X2","X3","X4","X5","X6","X7")
# 
# 
# ##########################################################
# # XGboost with default parameters
# ##########################################################
# # note to start nrounds from 200, as smaller learning rates result in errors so
# # big with lower starting points that they'll mess the scales
# tune_grid <- expand.grid(
#   nrounds = seq(from = 200, to = 450, by = 50),
#   eta = c(0.032),
#   max_depth = c(3),
#   gamma = c(0),
#   colsample_bytree = c(1),
#   min_child_weight = c(16),
#   subsample = c(0.8)
# )
# 
# tune_control <- caret::trainControl(
#   method = "cv", # cross-validation
#   number = 5, # with n folds
#   #index = createFolds(tr_treated$Id_clean), # fix the folds
#   verboseIter = FALSE, # no training log
#   allowParallel = TRUE, # FALSE for reproducible results
#   classProbs=TRUE,
#   summaryFunction = multiClassSummary
# )
# 
# xgb_tune <- caret::train(
#   x = input_x,
#   y = input_y,
#   trControl = tune_control,
#   tuneGrid = tune_grid,
#   method = "xgbTree",
#   verbose = TRUE,
#   metric="logLoss"
# )
# 
# # helper function for the plots
# tuneplot <- function(x, probs = .90) {
#   ggplot(x) +
#     coord_cartesian(ylim = c(quantile(x$results$logLoss, probs = probs), min(x$results$logLoss))) +
#     theme_bw()
# }
# 
# tuneplot(xgb_tune)
# xgb_tune$bestTune
# min(xgb_tune$results$logLoss)
# library(beepr)
# beep(6)
# toc()
```

#Drop exblue's
```{r}
# ICLR_train[,c(258:270)] <- NULL
# ICLR_test[,c(258:270)] <- NULL
```

#Save for Alchemi
```{r}
# save(ICLR_train,ICLR_test, file="ICLR_Alchemi.rda")
```


#Cross validation or xgboost

```{r}
# library(ggplot2) # Data visualization
# library(data.table)
# library(xgboost)
# library(caret)
# library(Matrix)
# 
# 
# #Remove Field ID from train features
# Train_XG <- ICLR_train[,-c(1)]
# # Train_XG <- ICLR_train
# 
# table(Train_XG$label)
# Test_XG <- ICLR_test[,-c(1,2)]
# 
# train = Train_XG #training partition
# 
# #Create Matrix
# dtrain <- sparse.model.matrix(label ~ . -1, data = train)
# feature_names <- names(dtrain)
# target <- as.numeric(train[,"label"])-1
# dtrain <- xgb.DMatrix( data = as.matrix(dtrain), label = target, missing= NA)
# 
# ###################
# #XG Boost setup 
# ###################
# 
# dtest_F <- xgb.DMatrix(data=as.matrix( Test_XG))
# 
# ###################
# #Cross Validation
# ###################
# # Set up cross-validation scheme (3-fold)
# foldsCV <- createFolds(target, k=5, list=TRUE, returnTrain=FALSE)
# 
# 
#   param <- list(booster = "gbtree"
#               , objective = "multi:softprob"
#               , subsample = 0.85 #0.8
#               , max_depth = 3
#               , colsample_bytree = 0.95 #0.95,1
#               , eta = 0.032
#               #, lambda = 0.08
#               , eval_metric = 'mlogloss'
#               , num_class = 7
#               , gamma = 0
#               #, base_score = 0.012 #average
#               , min_child_weight = 2#2,16
#                 )
# xgb_cv <- xgb.cv(data=dtrain,
#                    params=param,
#                   nrounds=500,
#                   prediction=TRUE,
#                   maximize=FALSE,
#                   folds=foldsCV,
#                   early_stopping_rounds = 20,
#                   print_every_n = 5
#   )
# 
# 
#   # Check best results and get best nrounds
#   # print(xgb_cv$evaluation_log[which.min(xgb_cv$evaluation_log$test_mae_mean)])
# # nrounds <- xgb_cv$best_iteration
```

#Try 1600,1700. Bad at 2000
```{r}

#   ################
#   # Final model
#   ################
#   set.seed(987654321)
#   xgb <- xgboost::xgboost(params = param
#                    , data = dtrain
#                   # , watchlist = list(train = dtrain)
#                    , nrounds = 500#500,751
#                    , verbose = 1
#                    , print_every_n = 2
#                    #, feval = amm_mae
#                   )
#   ###############
#   # Results
#   ###############
#   #Feature imprtance
#   imp <- xgb.importance(feature_names, model =xgb)
#   imp
#   xgb.plot.importance(imp)
#   # imp$Feature
#   
#   
#   #Submission
#   test_new <- as.matrix(Test_XG)
# 
#   
#   #Prep for submit
#   Check_XG <- predict(xgb, newdata = test_new)
#   Check_XG <- as.data.frame(matrix(Check_XG,ncol =7, byrow=T))
#   ICLR_Submit <- cbind(ICLR_test,Check_XG)
#   c1<- ncol(ICLR_Submit)-6
#   c2<- ncol(ICLR_Submit)
#   ICLR_Submit <- ICLR_Submit[,c(1,c1:c2)]
# 
#   #Group 
#   ICLR_Submit <- ICLR_Submit %>% group_by(Field_ID) %>% summarise_all(funs(mean))
#   table(ICLR_train$class)
#   colnames(ICLR_Submit)[2:8] <-c('Crop_ID_1','Crop_ID_2','Crop_ID_3','Crop_ID_4','Crop_ID_5','Crop_ID_6','Crop_ID_7')
#   
# 
# 
# write.csv(ICLR_Submit, file = "C:/Users/A199702/Documents/Zindi/Crop Recognition/ICLR_Submit.csv", row.names = F)
# beep(6)

```
#Catboost
```{r}

#Take random 1% of remainder
set.seed(123456)
partition = createDataPartition(ICLR_train[,"label"], times = 1, p = 1 , list = F)
training = ICLR_train[partition,] #take random 1% i.e. 1m obs
testing = ICLR_train[-partition,] #take random 1% i.e. 1m obs

##############################
#Model 1: Runs for 1hr 15mins
##############################
# training <- ICLR_train
train_pool <- catboost.load_pool(data = training[,-c(1,2)], label = training$label)
test_pool <- catboost.load_pool(data = testing[,-c(1,2)], label = testing$label)
fit_params <- list(
  iterations = 1700, #500 557,360
  loss_function = "MultiClass",
  # learning_rate = 0.3,
  # eval_metric = "Logloss",#F1,Logloss
  random_seed = 999,
  use_best_model = T,
  prediction_type = "Probability" #Probability or Class
  #border = 0.5
)

CB_model_1 <- catboost.train(train_pool, NULL, fit_params)#
save(CB_model_1, file= "CB_model_1.rda") #360 stop
# load(file= "CB_model_1.rda")
beep(6)

CB_model_1_imp <- catboost.get_feature_importance(CB_model_1, 
                                pool = NULL, 
                                type = 'FeatureImportance',
                                thread_count = -1)


```

#Submit file
You can skip modeling by loading the models commented below
```{r}
#Uncomment this to skip training
# load(file= "CB_model_1.rda")#Load model 1
# load(file= "CB_model_2.rda") #Load model 2

#Submit
# submit_pool <- catboost.load_pool(data = Sanral_Submit[,-c(1:3,9,15,17)])
submit_pool <- catboost.load_pool(data = ICLR_test[,-c(1,2)])
# submit_pool_2 <- catboost.load_pool(data = Sanral_Submit[,c(4,6:8)])


# submit_pool <- catboost.load_pool(data = Sanral_Submit[,-c(1:15,17)])

Check_XG <- catboost.predict(CB_model_1, submit_pool,prediction_type = "Probability")
# Final_submit_2 <- catboost.predict(CB_model_2, submit_pool_2,prediction_type = "Probability")

 #Prep for submit
  ICLR_Submit <- cbind(ICLR_test,Check_XG)
  c1<- ncol(ICLR_Submit)-6
  c2<- ncol(ICLR_Submit)
  ICLR_Submit <- ICLR_Submit[,c(1,c1:c2)]

  #Group 
  ICLR_Submit <- ICLR_Submit %>% group_by(Field_ID) %>% summarise_all(funs(mean))
  table(ICLR_train$class)
  colnames(ICLR_Submit)[2:8] <-c('Crop_ID_1','Crop_ID_2','Crop_ID_3','Crop_ID_4','Crop_ID_5','Crop_ID_6','Crop_ID_7')
  


write.csv(ICLR_Submit, file = "C:/Users/A199702/Documents/Zindi/Crop Recognition/ICLR_Catboost_1700_1.1603.csv", row.names = F)

beep(6)
```

```{r}
s
```

